import click
import asyncio
import json
import yaml
from pathlib import Path
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.table import Table
from rich.panel import Panel

from ..llm.model_router import ModelRouter
from ..prompts.manager import PromptManager
from ..crawler.arxiv_crawler import ArxivCrawler
from ..analyzer.requirement_analyzer import RequirementAnalyzer
from ..analyzer.classifier import PaperClassifier
from ..reviewer.generator import ReviewGenerator
from ..core.models import SearchQuery, TaskType
from ..utils.config_utils import setup_proxy_config
from ..utils.llm_logger import get_llm_logger

console = Console()

@click.group()
@click.version_option(version="1.0.0")
def cli():
    """AIæ–‡çŒ®è‡ªåŠ¨çˆ¬å–åŠ©æ‰‹ - æ™ºèƒ½æ–‡çŒ®è°ƒç ”å·¥å…·"""
    pass

@cli.command()
@click.argument('query')
@click.option('--max-papers', default=20, help='æœ€å¤§çˆ¬å–è®ºæ–‡æ•°é‡')
@click.option('--model', help='æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹ (æ ¼å¼: provider_name/model_name, å¦‚: openai_proxy/gpt-4)')
@click.option('--output', default='./papers.json', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
@click.option('--config', default='config/config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
def search(query, max_papers, model, output, config):
    """æœç´¢å¹¶åˆ†ææ–‡çŒ®"""
    asyncio.run(_search_papers(query, max_papers, model, output, config))

async def _search_papers(query: str, max_papers: int, model: str, output: str, config_path: str):
    """æœç´¢è®ºæ–‡çš„å¼‚æ­¥å®ç°"""
    try:
        console.print(Panel(f"[bold blue]å¼€å§‹æ–‡çŒ®æœç´¢ï¼š{query}[/bold blue]", expand=False))
        
        # åˆå§‹åŒ–ç»„ä»¶
        model_router, prompt_manager = await _initialize_components(config_path)
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            
            # æ­¥éª¤1ï¼šåˆ†æç”¨æˆ·éœ€æ±‚
            task1 = progress.add_task("åˆ†æç ”ç©¶éœ€æ±‚...", total=None)
            analyzer = RequirementAnalyzer(model_router, prompt_manager)
            requirement = await analyzer.analyze_requirement(query, model)
            progress.update(task1, description="éœ€æ±‚åˆ†æå®Œæˆ")
            
            # æ˜¾ç¤ºåˆ†æç»“æœ
            _display_requirement_analysis(requirement)
            
            # æ­¥éª¤2ï¼šçˆ¬å–è®ºæ–‡
            task2 = progress.add_task("çˆ¬å–ArXivè®ºæ–‡...", total=None)
            async with ArxivCrawler() as crawler:
                # ä½¿ç”¨åˆ†æå¾—åˆ°çš„æœç´¢æŸ¥è¯¢
                search_queries = requirement.search_queries[:3]  # ä½¿ç”¨å‰3ä¸ªæŸ¥è¯¢
                all_papers = []
                
                for search_query in search_queries:
                    query_obj = SearchQuery(
                        query_string=search_query,
                        max_results=max_papers // len(search_queries)
                    )
                    result = await crawler.fetch_papers(query_obj)
                    all_papers.extend(result.papers)
                
                # å»é‡
                unique_papers = crawler.remove_duplicates(all_papers)
                papers = unique_papers[:max_papers]
            
            progress.update(task2, description=f"çˆ¬å–å®Œæˆ ({len(papers)}ç¯‡è®ºæ–‡)")
            
            # è®°å½•çˆ¬å–åˆ°çš„ArXivé“¾æ¥
            llm_logger = get_llm_logger()
            llm_logger.log_arxiv_links(papers)
            
            # æ­¥éª¤3ï¼šåˆ†ç±»è®ºæ–‡
            task3 = progress.add_task("åˆ†ç±»å’Œåˆ†æè®ºæ–‡...", total=None)
            classifier = PaperClassifier(model_router, prompt_manager)
            classifications = await classifier.classify_papers(papers, model)
            progress.update(task3, description="è®ºæ–‡åˆ†ç±»å®Œæˆ")
        
        # æ˜¾ç¤ºç»“æœ
        _display_search_results(papers, classifications)
        
        # ä¿å­˜ç»“æœ
        _save_results(papers, classifications, requirement, output)
        
        console.print(f"\n[green]æœç´¢å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° {output}[/green]")
        
    except Exception as e:
        console.print(f"[red]æœç´¢å¤±è´¥: {str(e)}[/red]")

@cli.command()
@click.option('--input', default='./papers.json', help='è®ºæ–‡æ•°æ®æ–‡ä»¶è·¯å¾„')
@click.option('--output', default='./review.md', help='ç»¼è¿°è¾“å‡ºæ–‡ä»¶è·¯å¾„')
@click.option('--model', help='æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹')
@click.option('--config', default='config/config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
def review(input_file, output, model, config):
    """ç”Ÿæˆæ–‡çŒ®ç»¼è¿°"""
    asyncio.run(_generate_review(input_file, output, model, config))

async def _generate_review(input_file: str, output: str, model: str, config_path: str):
    """ç”Ÿæˆç»¼è¿°çš„å¼‚æ­¥å®ç°"""
    try:
        console.print(Panel("[bold blue]å¼€å§‹ç”Ÿæˆæ–‡çŒ®ç»¼è¿°[/bold blue]", expand=False))
        
        # åŠ è½½è®ºæ–‡æ•°æ®
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        papers = [paper for paper in data['papers']]
        classifications = [cls for cls in data['classifications']]
        requirement = data['requirement']
        
        # åˆå§‹åŒ–ç»„ä»¶
        model_router, prompt_manager = await _initialize_components(config_path)
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            
            task = progress.add_task("ç”Ÿæˆç»¼è¿°ä¸­...", total=None)
            
            # ç”Ÿæˆç»¼è¿°
            generator = ReviewGenerator(model_router, prompt_manager)
            
            # é‡å»ºå¯¹è±¡ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            from ..core.models import Paper, PaperClassification, ResearchRequirement
            paper_objects = [Paper(**p) for p in papers]
            classification_objects = [PaperClassification(**c) for c in classifications]
            requirement_object = ResearchRequirement(**requirement)
            
            review = await generator.generate_literature_review(
                paper_objects, classification_objects, requirement_object, model
            )
            
            progress.update(task, description="ç»¼è¿°ç”Ÿæˆå®Œæˆ")
        
        # ä¿å­˜ç»¼è¿°
        markdown_content = generator.export_to_markdown(review)
        with open(output, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        console.print(f"\n[green]ç»¼è¿°å·²ç”Ÿæˆå¹¶ä¿å­˜åˆ° {output}[/green]")
        console.print(f"ğŸ“Š ç»¼è¿°ç»Ÿè®¡: {review.word_count} å­—")
        
    except Exception as e:
        console.print(f"[red]ç»¼è¿°ç”Ÿæˆå¤±è´¥: {str(e)}[/red]")

@cli.command()
@click.option('--config', default='config/config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
def test_models(config):
    """æµ‹è¯•æ¨¡å‹è¿æ¥"""
    asyncio.run(_test_models(config))

async def _test_models(config_path: str):
    """æµ‹è¯•æ¨¡å‹è¿æ¥çš„å¼‚æ­¥å®ç°"""
    try:
        model_router, _ = await _initialize_components(config_path)
        
        console.print(Panel("[bold blue]æµ‹è¯•æ¨¡å‹è¿æ¥[/bold blue]", expand=False))
        
        results = model_router.test_all_connections()
        
        table = Table(title="æ¨¡å‹è¿æ¥çŠ¶æ€")
        table.add_column("æ¨¡å‹", style="cyan")
        table.add_column("çŠ¶æ€", style="magenta")
        
        for model_name, is_connected in results.items():
            status = "è¿æ¥æ­£å¸¸" if is_connected else "è¿æ¥å¤±è´¥"
            table.add_row(model_name, status)
        
        console.print(table)
        
    except Exception as e:
        console.print(f"[red]æµ‹è¯•å¤±è´¥: {str(e)}[/red]")

@cli.command()
@click.option('--config', default='config/config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
def stats(config):
    """æ˜¾ç¤ºä½¿ç”¨ç»Ÿè®¡"""
    asyncio.run(_show_stats(config))

@cli.command()
@click.option('--api-key', required=True, help='ä»£ç†æœåŠ¡çš„APIå¯†é’¥')
@click.option('--base-url', required=True, help='ä»£ç†æœåŠ¡çš„base_url')
@click.option('--config', default='config/config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
def setup_proxy(api_key, base_url, config):
    """å¿«é€Ÿé…ç½®ç¬¬ä¸‰æ–¹ä»£ç†"""
    _setup_proxy_config(api_key, base_url, config)

@cli.command()
@click.option('--config', default='config/config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
def list_models(config):
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"""
    asyncio.run(_list_models(config))

async def _show_stats(config_path: str):
    """æ˜¾ç¤ºç»Ÿè®¡çš„å¼‚æ­¥å®ç°"""
    try:
        model_router, _ = await _initialize_components(config_path)
        
        console.print(Panel("[bold blue]ä½¿ç”¨ç»Ÿè®¡[/bold blue]", expand=False))
        
        stats_data = model_router.get_all_stats()
        
        table = Table(title="æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡")
        table.add_column("æ¨¡å‹", style="cyan")
        table.add_column("è¯·æ±‚æ•°", style="magenta")
        table.add_column("æˆåŠŸç‡", style="green")
        table.add_column("æ€»æˆæœ¬", style="yellow")
        
        for model_name, stats in stats_data.items():
            success_rate = f"{stats['success_rate']:.2%}"
            total_cost = f"${stats['total_cost']:.4f}"
            table.add_row(
                model_name, 
                str(stats['request_count']), 
                success_rate, 
                total_cost
            )
        
        console.print(table)
        
    except Exception as e:
        console.print(f"[red]âŒ ç»Ÿè®¡æ˜¾ç¤ºå¤±è´¥: {str(e)}[/red]")

async def _initialize_components(config_path: str):
    """åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶"""
    # åˆå§‹åŒ–æ¨¡å‹è·¯ç”±å™¨
    model_router = ModelRouter()
    
    # åŠ è½½é»˜è®¤é…ç½®ï¼ˆå¦‚æœé…ç½®æ–‡ä»¶å­˜åœ¨ï¼‰
    if Path(config_path).exists():
        model_router.load_config(config_path)
    else:
        # åˆ›å»ºé»˜è®¤é…ç½®
        _create_default_config(config_path)
    
    # åˆå§‹åŒ–æç¤ºè¯ç®¡ç†å™¨
    prompt_manager = PromptManager()
    
    return model_router, prompt_manager

def _create_default_config(config_path: str):
    """åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"""
    default_config = {
        "models": {
            "openai_gpt4": {
                "provider": "openai",
                "model_name": "gpt-4",
                "api_key": "${OPENAI_API_KEY}",
                "temperature": 0.7,
                "max_tokens": 4000
            }
        },
        "task_preferences": {
            "requirement_analysis": ["openai_gpt4"],
            "paper_classification": ["openai_gpt4"],
            "review_generation": ["openai_gpt4"]
        }
    }
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    Path(config_path).parent.mkdir(parents=True, exist_ok=True)
    
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(default_config, f, allow_unicode=True, default_flow_style=False)

def _display_requirement_analysis(requirement):
    """æ˜¾ç¤ºéœ€æ±‚åˆ†æç»“æœ"""
    console.print("\n[bold yellow]éœ€æ±‚åˆ†æç»“æœ:[/bold yellow]")
    
    table = Table(show_header=False, box=None)
    table.add_column("é¡¹ç›®", style="cyan", width=15)
    table.add_column("å†…å®¹", style="white")
    
    table.add_row("ç ”ç©¶é¢†åŸŸ", ", ".join(requirement.research_domains))
    table.add_row("å…·ä½“ä¸»é¢˜", ", ".join(requirement.specific_topics))
    table.add_row("å…³é”®è¯", ", ".join(requirement.keywords))
    table.add_row("é¢„æœŸè®ºæ–‡æ•°", str(requirement.paper_count_estimate))
    
    console.print(table)

def _display_search_results(papers, classifications):
    """æ˜¾ç¤ºæœç´¢ç»“æœ"""
    console.print(f"\n[bold yellow]ğŸ“š æ‰¾åˆ° {len(papers)} ç¯‡ç›¸å…³è®ºæ–‡:[/bold yellow]")
    
    # åˆ›å»ºåˆ†ç±»ç»Ÿè®¡
    from collections import defaultdict
    domain_counts = defaultdict(int)
    for cls in classifications:
        domain_counts[cls.primary_domain] += 1
    
    # æ˜¾ç¤ºé¢†åŸŸåˆ†å¸ƒ
    table = Table(title="ç ”ç©¶é¢†åŸŸåˆ†å¸ƒ")
    table.add_column("é¢†åŸŸ", style="cyan")
    table.add_column("è®ºæ–‡æ•°é‡", style="magenta")
    
    for domain, count in sorted(domain_counts.items(), key=lambda x: x[1], reverse=True):
        table.add_row(domain, str(count))
    
    console.print(table)
    
    # æ˜¾ç¤ºé«˜è´¨é‡è®ºæ–‡
    high_quality_papers = [
        (papers[i], classifications[i]) 
        for i in range(len(papers)) 
        if i < len(classifications) and classifications[i].relevance_score > 7.0
    ]
    
    if high_quality_papers:
        console.print(f"\n[bold green]â­ é«˜è´¨é‡è®ºæ–‡ (è¯„åˆ†>7.0):[/bold green]")
        for i, (paper, cls) in enumerate(high_quality_papers[:5]):
            console.print(f"{i+1}. [bold]{paper.title}[/bold]")
            console.print(f"   è¯„åˆ†: {cls.relevance_score:.1f} | é¢†åŸŸ: {cls.primary_domain}")
            console.print(f"   [link]{paper.url}[/link]\n")

def _save_results(papers, classifications, requirement, output_path: str):
    """ä¿å­˜æœç´¢ç»“æœ"""
    # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
    papers_data = []
    for paper in papers:
        papers_data.append({
            'title': paper.title,
            'authors': paper.authors,
            'abstract': paper.abstract,
            'arxiv_id': paper.arxiv_id,
            'url': paper.url,
            'pdf_url': paper.pdf_url,
            'published_date': paper.published_date,
            'categories': paper.categories
        })
    
    classifications_data = []
    for cls in classifications:
        classifications_data.append({
            'paper_id': cls.paper_id,
            'primary_domain': cls.primary_domain,
            'sub_domains': cls.sub_domains,
            'research_type': cls.research_type.value,
            'technical_approaches': cls.technical_approaches,
            'relevance_score': cls.relevance_score,
            'keywords_extracted': cls.keywords_extracted,
            'application_areas': cls.application_areas,
            'novelty_level': cls.novelty_level.value,
            'citation_potential': cls.citation_potential
        })
    
    requirement_data = {
        'user_input': requirement.user_input,
        'research_domains': requirement.research_domains,
        'specific_topics': requirement.specific_topics,
        'keywords': requirement.keywords,
        'time_preference': requirement.time_preference,
        'paper_count_estimate': requirement.paper_count_estimate,
        'research_focus': requirement.research_focus,
        'search_queries': requirement.search_queries
    }
    
    result_data = {
        'papers': papers_data,
        'classifications': classifications_data,
        'requirement': requirement_data,
        'summary': {
            'total_papers': len(papers),
            'domains_found': len(set(cls.primary_domain for cls in classifications)),
            'avg_relevance_score': sum(cls.relevance_score for cls in classifications) / len(classifications) if classifications else 0
        }
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2)

def _setup_proxy_config(api_key: str, base_url: str, config_path: str):
    """é…ç½®ä»£ç†è®¾ç½®"""
    try:
        console.print(Panel("[bold blue]é…ç½®ç¬¬ä¸‰æ–¹ä»£ç†[/bold blue]", expand=False))
        
        # éªŒè¯base_urlæ ¼å¼
        if not (base_url.startswith("http://") or base_url.startswith("https://")):
            console.print("[red]âŒ base_url å¿…é¡»ä»¥ http:// æˆ– https:// å¼€å¤´[/red]")
            return
        
        # æ·»åŠ é…ç½®åˆ°.envæ–‡ä»¶
        result = setup_proxy_config(api_key, base_url)
        console.print(f"[green]âœ… {result}[/green]")
        
        # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
        console.print("\n[yellow]ä½¿ç”¨è¯´æ˜:[/yellow]")
        console.print("1. ç°åœ¨å¯ä»¥ä½¿ç”¨ä»£ç†æ¨¡å‹äº†ï¼ˆå¦‚ openai_gpt4_proxyï¼‰")
        console.print("2. ä»£ç†æ¨¡å‹åœ¨ä»»åŠ¡åå¥½ä¸­æ‹¥æœ‰æ›´é«˜ä¼˜å…ˆçº§")
        console.print("3. æµ‹è¯•è¿æ¥: python main.py test-models")
        console.print("4. å¼€å§‹æœç´¢: python main.py search \"ä½ çš„ç ”ç©¶é—®é¢˜\"")
        
        # æµ‹è¯•ä»£ç†è¿æ¥
        console.print("\n[cyan]æµ‹è¯•ä»£ç†è¿æ¥...[/cyan]")
        try:
            model_router = ModelRouter()
            if Path(config_path).exists():
                model_router.load_config(config_path)
            
            # æµ‹è¯•ä»£ç†æ¨¡å‹
            proxy_models = [name for name in model_router.providers.keys() if 'proxy' in name]
            if proxy_models:
                for model_name in proxy_models[:1]:  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªä»£ç†æ¨¡å‹
                    is_working = model_router.providers[model_name].test_connection()
                    status = "âœ… è¿æ¥æ­£å¸¸" if is_working else "âŒ è¿æ¥å¤±è´¥"
                    console.print(f"  {model_name}: {status}")
            else:
                console.print("[yellow]  æ²¡æœ‰æ‰¾åˆ°ä»£ç†æ¨¡å‹é…ç½®[/yellow]")
                
        except Exception as e:
            console.print(f"[yellow]  è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}[/yellow]")
        
    except Exception as e:
        console.print(f"[red]âŒ é…ç½®å¤±è´¥: {str(e)}[/red]")

async def _list_models(config_path: str):
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹"""
    try:
        console.print(Panel("[bold blue]å¯ç”¨æ¨¡å‹åˆ—è¡¨[/bold blue]", expand=False))
        
        model_router = ModelRouter()
        if Path(config_path).exists():
            model_router.load_config(config_path)
        
        available_models = model_router.get_available_models()
        
        if not available_models:
            console.print("[yellow]æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·æ£€æŸ¥é…ç½®å’ŒAPIå¯†é’¥[/yellow]")
            return
        
        for provider_name, models in available_models.items():
            console.print(f"\n[bold cyan]{provider_name}[/bold cyan]")
            
            provider_config = model_router.app_config.providers.get(provider_name)
            if provider_config:
                console.print(f"   ç±»å‹: {provider_config.provider_type}")
                if provider_config.base_url:
                    console.print(f"   åœ°å€: {provider_config.base_url}")
                console.print(f"   æ¨¡å‹æ•°é‡: {len(models)}")
                
                # æ˜¾ç¤ºæ¯ä¸ªæ¨¡å‹
                for model_name in models:
                    model_ref = f"{provider_name}/{model_name}"
                    model_info = model_router.get_model_info(model_ref)
                    
                    if model_info:
                        cost_info = f"${model_info.cost_per_1k_input:.3f}/${model_info.cost_per_1k_output:.3f}"
                        console.print(f"     {model_info.display_name} ({model_name}) - {cost_info}/1k tokens")
                    else:
                        console.print(f"     {model_name}")
        
        # æ˜¾ç¤ºä»»åŠ¡åå¥½
        console.print(f"\n[bold green]ä»»åŠ¡åå¥½é…ç½®[/bold green]")
        for task_name, preferred_models in model_router.app_config.task_preferences.items():
            console.print(f"   {task_name}:")
            for i, model_ref in enumerate(preferred_models[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                console.print(f"     {i+1}. {model_ref}")
            if len(preferred_models) > 3:
                console.print(f"     ... (+{len(preferred_models)-3} æ›´å¤š)")
        
        # ä½¿ç”¨ç¤ºä¾‹
        console.print(f"\n[bold yellow]ä½¿ç”¨ç¤ºä¾‹[/bold yellow]")
        if available_models:
            first_provider = list(available_models.keys())[0]
            first_model = available_models[first_provider][0]
            example_ref = f"{first_provider}/{first_model}"
            console.print(f"   python main.py search \"ç ”ç©¶é—®é¢˜\" --model {example_ref}")
        
    except Exception as e:
        console.print(f"[red]âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}[/red]")

if __name__ == '__main__':
    cli()